{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d91bb2-6a05-41cd-9b46-b68babc9adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a07974-7efc-4f1d-8a7d-aefa616dbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base path to thumb drive (input path)\n",
    "base_path = '/Volumes/Untitled/MeterDataTest'\n",
    "#base_path = '/Desktop/MeterDataTest'\n",
    "\n",
    "#check if base path exists\n",
    "if not os.path.exists(base_path):\n",
    "    print(f\"Error: Path {base_path} does not exist\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd34a68-6c88-4a8c-a818-d0b0a9d2af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dataframes of each meter\n",
    "meter_dfs = []\n",
    "\n",
    "# list to store all dataframes of each meter\n",
    "all_data = []\n",
    "\n",
    "#list to store all dataframes with 3_phase_watt_total column for later use\n",
    "save_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a9ac9a-3aa6-47db-83be-812213b81f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the subfolders in the MeterDataTest folder\n",
    "for subfolder in os.listdir(base_path):\n",
    "    # create path for each subfolder\n",
    "    folder_path = os.path.join(base_path, subfolder)\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    # get the name of the meter from the subfolder name, make lowercase\n",
    "    meter_name = subfolder.lower().replace(\" \", \"_\").replace(\"_mtr\", \"\")\n",
    "    #print(meter_name)\n",
    "\n",
    "    # list of csv file paths in subfolder\n",
    "    # addition with the 'and not' is to make sure to ignore the hidden ._ files\n",
    "    csv_paths = [os.path.join(folder_path, f) \n",
    "                 for f in os.listdir(folder_path) \n",
    "                 if f.endswith('.csv')\n",
    "                 and not f.startswith(\"._\")\n",
    "                 and not f.startswith(\".\")]\n",
    "\n",
    "    # empty meter's dataframe list\n",
    "    meter_dfs = []\n",
    "    \n",
    "    # convert each csv to a df, fix columns and add df to df list\n",
    "    for csv in csv_paths:\n",
    "        temp_df = pd.read_csv(csv, encoding=\"utf-8\")\n",
    "\n",
    "        temp_df.columns = temp_df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "        \n",
    "        # rename columns if they exist\n",
    "        # some meters have have the different label but they are synonymous\n",
    "        if '3_phase_positive_real_energy_used' in temp_df.columns:\n",
    "            temp_df.rename(columns={\n",
    "                '3_phase_positive_real_energy_used': 'total_watt_hour',\n",
    "                '3_phase_real_power':'3_phase_watt_total'\n",
    "            }, inplace=True)\n",
    "\n",
    "        # error in scripts, total_watt_hour is actually total kwh\n",
    "        temp_df.rename(columns={'total_watt_hour': 'kwh'}, inplace=True)\n",
    "        \n",
    "        # reorder the columns\n",
    "        temp_df = temp_df[['datetime', 'kwh', '3_phase_watt_total']]\n",
    "        temp_df.insert(1, 'meter_name', meter_name)\n",
    "\n",
    "        meter_dfs.append(temp_df)\n",
    "\n",
    "    # combine all csvs for this meter into one dataframe\n",
    "    df = pd.concat(meter_dfs, ignore_index=True)\n",
    "    \n",
    "    # save the dataframe with all columns to list\n",
    "    save_data.append(df.copy())\n",
    "    df.drop('3_phase_watt_total', axis=1, inplace=True)\n",
    "\n",
    "    # convert datetime column to a datetime type\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # create column that contains the closest interval for each timestamp (contains ymd hms, using timedelta)\n",
    "    #df['interval_15min'] = pd.to_datetime(df['datetime'].dt.round('15min'), format='%Y-%m-%d %H:%M:%S')\n",
    "    df['interval_15min'] = df['datetime'].dt.round('15min')\n",
    "    \n",
    "    # create column that contains the offset in seconds from the closest interval for each timestamp\n",
    "    # - is if its before it and + is if its after\n",
    "    df['interval_offset'] = (df['datetime'] - df['interval_15min']).dt.total_seconds()\n",
    "\n",
    "    # create new column with true if an exact interval and false if not\n",
    "    df['is_exact'] = df['datetime'].eq(df['interval_15min'])\n",
    "    \n",
    "    df['interpolated'] = False\n",
    "    \n",
    "    interpolated_rows = []\n",
    "\n",
    "    # interval = the 15min bucket val, group = all rows in that bucket\n",
    "    for interval, group in df.groupby('interval_15min'):\n",
    "        # only select rows in group with is_exact == True\n",
    "        exact = group[group['is_exact']]\n",
    "\n",
    "        if exact.empty:\n",
    "            before = group[group['interval_offset'] <= 0]\n",
    "            after = group[group['interval_offset'] >= 0]\n",
    "\n",
    "            # check if there are empties\n",
    "            if not before.empty and not after.empty:\n",
    "                # grab the closest data to the interval\n",
    "                time_before = before.iloc[-1]\n",
    "                time_after = after.iloc[0]\n",
    "                \n",
    "                # calculate the estimated kwh\n",
    "                # get the slope to 4 decimal places\n",
    "                reading_diff = time_after['kwh'] - time_before['kwh']\n",
    "\n",
    "                if reading_diff == 0:\n",
    "                    estimated_twh = time_before['kwh']\n",
    "                else:\n",
    "                    time_diff = (time_after['datetime'] - time_before['datetime']).total_seconds()\n",
    "                    slope = round(reading_diff / time_diff, 4)\n",
    "                    sec_before_interval = (interval - time_before['datetime']).total_seconds()\n",
    "                    estimated_twh = time_before['kwh'] + (slope * sec_before_interval)\n",
    "\n",
    "                # create interpolated row\n",
    "                new_row = time_before.copy()\n",
    "                new_row['datetime'] = interval\n",
    "                new_row['kwh'] = estimated_twh\n",
    "                new_row['interval_offset'] = 0\n",
    "                new_row['is_exact'] = True\n",
    "                new_row['interpolated'] = True\n",
    "                \n",
    "                # add new interpolated row to list\n",
    "                interpolated_rows.append(new_row)\n",
    "\n",
    "    # combine interpolated data with dataframe\n",
    "    if interpolated_rows:\n",
    "        \n",
    "        df = pd.concat([df, pd.DataFrame(interpolated_rows)], ignore_index=True)\n",
    "\n",
    "    df = df.drop(columns=['interval_15min', 'interval_offset'])\n",
    "\n",
    "    # resort the data to be in order of datetime\n",
    "    df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "    \n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a7ba6-105a-472b-b448-eda33fdae02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for all data\n",
    "combined_data = pd.DataFrame()\n",
    "save_data_col = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cad92-2057-4e24-962a-c34e1119bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create with all columns to save for later\n",
    "save_data_col = pd.concat(save_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccaa2e-de47-4dc1-9713-0bc59ed3851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dataframes in list to one dataframe\n",
    "combined_data = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc40bad-c23d-4d6f-a434-764d5ef23f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check there is only one instance\n",
    "print(combined_data[(combined_data['meter_name'] == 'admin_serv_1_mtr') &\n",
    "    (combined_data['datetime'] == pd.to_datetime('2025-07-23 09:40:50'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7f372-6e72-4805-ad39-dff0e13c75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for if there exists duplicates\n",
    "duplicate_data = combined_data[combined_data.duplicated(keep=False)]\n",
    "print(duplicate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad61a0f-a33e-4e23-8f17-3dd97eecd14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993984ec-ca33-47de-9e98-b677b16258bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe with all collumns to csv to save for later\n",
    "save_data_col.to_csv('save_data_col.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82582ae7-b07a-494c-bacf-d79ecee576c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to csv\n",
    "combined_data.to_csv('interpolated_meter_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bf447-12b9-43f2-9c77-83e9bd039cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce184da-6e00-40b8-a16c-d568ba738433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of meters and first timestamp in dataset\n",
    "df = pd.read_csv('interpolated_meter_data.csv', encoding=\"utf-8\")\n",
    "print(df['meter_name'].unique())\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd8170-b0e2-42c1-8625-2a11b04d867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample of interpolated data for admin_serv_1 2025-09-10\n",
    "df = pd.read_csv('interpolated_meter_data.csv', encoding=\"utf-8\")\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "date = pd.to_datetime('2025-09-10').date()\n",
    "sample_data = df[(df['datetime'].dt.date == date) & (df['meter_name'] == 'admin_serv_1_mtr')]\n",
    "sample_data.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f732792-7151-4b6e-89a9-cd27823f82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample of interpolated data for biomedical_science_main_a_mtr 2025-09-10\n",
    "df = pd.read_csv('interpolated_meter_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcfff8-049e-4bb7-810f-0f83b11817fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "date = pd.to_datetime('2025-09-10').date()\n",
    "sample_data = df[(df['datetime'].dt.date == date) \n",
    "    & (df['meter_name'] == 'biomedical_science_main_a_mtr') \n",
    "    & ((df['interpolated'] == True) | ((df['datetime'].dt.minute % 15 == 0) & (df['datetime'].dt.second == 0)))\n",
    "    ].drop_duplicates(subset=['datetime', 'meter_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33b2be-b7cd-4252-80b1-25d2b509e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7928af-2a33-44f7-87d8-6e2993b240cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a93de1-5608-4eb6-b340-cc193d4c933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just interpolated meter data from all meters on days sept 07-09 2025\n",
    "df = pd.read_csv('interpolated_meter_data.csv', encoding='utf-8')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3409b349-1263-45ed-b000-044896b34294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['datetime'].dt.date.isin([\n",
    "    pd.to_datetime('2025-09-07').date(),\n",
    "    pd.to_datetime('2025-09-08').date(),\n",
    "    pd.to_datetime('2025-09-09').date()])]\n",
    "df = df[df['is_exact'] & True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2722fd53-51d4-4c31-a3ec-c47aa7f7aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   datetime         meter_name           kwh  is_exact  \\\n",
      "47585   2025-09-07 00:00:00       admin_serv_1  1.404952e+06      True   \n",
      "47601   2025-09-07 00:15:00       admin_serv_1  1.404953e+06      True   \n",
      "47617   2025-09-07 00:30:00       admin_serv_1  1.404955e+06      True   \n",
      "47633   2025-09-07 00:45:00       admin_serv_1  1.404957e+06      True   \n",
      "47649   2025-09-07 01:00:00       admin_serv_1  1.404959e+06      True   \n",
      "...                     ...                ...           ...       ...   \n",
      "8722916 2025-09-09 22:45:00  wist_annex_1_main  6.486340e+05      True   \n",
      "8722932 2025-09-09 23:00:00  wist_annex_1_main  6.486370e+05      True   \n",
      "8722948 2025-09-09 23:15:00  wist_annex_1_main  6.486390e+05      True   \n",
      "8722964 2025-09-09 23:30:00  wist_annex_1_main  6.486400e+05      True   \n",
      "8722980 2025-09-09 23:45:00  wist_annex_1_main  6.486420e+05      True   \n",
      "\n",
      "         interpolated  \n",
      "47585            True  \n",
      "47601            True  \n",
      "47617            True  \n",
      "47633            True  \n",
      "47649            True  \n",
      "...               ...  \n",
      "8722916          True  \n",
      "8722932          True  \n",
      "8722948          True  \n",
      "8722964          True  \n",
      "8722980          True  \n",
      "\n",
      "[23645 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e64a4f18-0911-49c8-97b0-1bae78218ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sept07-09_kwh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c00b-9e3c-4d42-8c9e-81ad271ff9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
