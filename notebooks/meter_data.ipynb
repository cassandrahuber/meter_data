{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d91bb2-6a05-41cd-9b46-b68babc9adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a07974-7efc-4f1d-8a7d-aefa616dbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base path to thumb drive (input path)\n",
    "base_path = '/Volumes/Untitled/MeterDataTest'\n",
    "#base_path = '/Desktop/MeterDataTest'\n",
    "\n",
    "#check if base path exists\n",
    "if not os.path.exists(base_path):\n",
    "    print(f\"Error: Path {base_path} does not exist\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd34a68-6c88-4a8c-a818-d0b0a9d2af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store all dataframes\n",
    "all_data = []\n",
    "\n",
    "#list to store all dataframes with 3_phase_watt_total column for later use\n",
    "save_data = []\n",
    "\n",
    "# dataframe for all data\n",
    "#combined_data = pd.DataFrame()\n",
    "#save_data_col = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4739ed4-23c3-45a8-b40f-5dd13e879d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the subfolders in the MeterDataTest folder\n",
    "for subfolder in os.listdir(base_path):\n",
    "    subfolder.replace(\" \", \"_\")\n",
    "    # create path for each subfolder\n",
    "    folder_path = os.path.join(base_path, subfolder)\n",
    "\n",
    "    # get the name of the meter from the subfolder name, make lowercase\n",
    "    meter_name = subfolder.lower().replace(\" \", \"_\") \n",
    "\n",
    "    # list of csv file paths in subfolder\n",
    "    # addition with the 'and not' is to make sure to ignore the hidden ._ files\n",
    "    csv_paths = [os.path.join(folder_path, f) \n",
    "                 for f in os.listdir(folder_path) \n",
    "                 if f.endswith('.csv')\n",
    "                 and not f.startswith(\"._\")\n",
    "                 and not f.startswith(\".\")]\n",
    "\n",
    "    # convert each csv to a df, fix columns and add df to df list\n",
    "    for csv in csv_paths:\n",
    "        df = pd.read_csv(csv, encoding=\"utf-8\")\n",
    "\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "        \n",
    "        # rename columns if they exist\n",
    "        if '3_phase_positive_real_energy_used' in df.columns:\n",
    "            df.rename(columns={\n",
    "                '3_phase_positive_real_energy_used': 'total_watt_hour',\n",
    "                '3_phase_real_power':'3_phase_watt_total'\n",
    "            }, inplace=True)\n",
    "        \n",
    "        # reorder the columns\n",
    "        df = df[['datetime', 'total_watt_hour', '3_phase_watt_total']]\n",
    "        df.insert(1, 'meter_name', meter_name)\n",
    "\n",
    "        # save the dataframe with all columns to list\n",
    "        save_data.append(df.copy())\n",
    "\n",
    "        df.drop('3_phase_watt_total', axis=1, inplace=True)\n",
    "\n",
    "        # convert datetime column to a datetime type\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # create column that contains the closest interval for each timestamp (contains ymd hms, using timedelta)\n",
    "        #df['interval_15min'] = pd.to_datetime(df['datetime'].dt.round('15min'), format='%Y-%m-%d %H:%M:%S')\n",
    "        df['interval_15min'] = df['datetime'].dt.round('15min')\n",
    "        \n",
    "        # create column that contains the offset in seconds from the closest interval for each timestamp\n",
    "        # - is if its before it and + is if its after\n",
    "        df['interval_offset'] = (df['datetime'] - df['interval_15min']).dt.total_seconds()\n",
    "\n",
    "        # create new column with true if an exact interval and false if not\n",
    "        df['is_exact'] = df['datetime'].eq(df['interval_15min'])\n",
    "        \n",
    "        df['interpolated'] = False\n",
    "        \n",
    "        interpolated_rows = []\n",
    "\n",
    "        # interval = the 15min bucket val, group = all rows in that bucket\n",
    "        for interval, group in df.groupby('interval_15min'):\n",
    "            # only select rows in group with is_exact == True\n",
    "            exact = group[group['is_exact']]\n",
    "\n",
    "            if exact.empty:\n",
    "                before = group[group['interval_offset'] <= 0]\n",
    "                after = group[group['interval_offset'] >= 0]\n",
    "\n",
    "                # check if there are empties\n",
    "                if not before.empty and not after.empty:\n",
    "                    # grab the closest data to the interval\n",
    "                    time_before = before.iloc[-1]\n",
    "                    time_after = after.iloc[0]\n",
    "                    \n",
    "                    # calculate the estimated total_watt_hour\n",
    "                    # get the slope to 4 decimal places\n",
    "                    reading_diff = time_after['total_watt_hour'] - time_before['total_watt_hour']\n",
    "\n",
    "                    if reading_diff == 0:\n",
    "                        estimated_twh = time_before['total_watt_hour']\n",
    "                    else:\n",
    "                        time_diff = (time_after['datetime'] - time_before['datetime']).total_seconds()\n",
    "                        slope = round(reading_diff / time_diff, 4)\n",
    "                        sec_before_interval = (interval - time_before['datetime']).total_seconds()\n",
    "                        estimated_twh = time_before['total_watt_hour'] + (slope * sec_before_interval)\n",
    "\n",
    "                    # create interpolated row\n",
    "                    new_row = time_before.copy()\n",
    "                    new_row['datetime'] = interval\n",
    "                    new_row['total_watt_hour'] = estimated_twh\n",
    "                    new_row['interval_offset'] = 0\n",
    "                    new_row['is_exact'] = True\n",
    "                    new_row['interpolated'] = True\n",
    "                    \n",
    "                    # add new interpolated row to list\n",
    "                    interpolated_rows.append(new_row)\n",
    "\n",
    "        # combine interpolated data with dataframe\n",
    "        if interpolated_rows:\n",
    "            df = pd.concat([df, pd.DataFrame(interpolated_rows)], ignore_index=True)\n",
    "\n",
    "        df = df.drop(columns=['interval_15min', 'interval_offset', 'is_exact'])\n",
    "\n",
    "        # resort the data to be in order of datetime\n",
    "        df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "        \n",
    "        all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cad92-2057-4e24-962a-c34e1119bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create with all columns to save for later\n",
    "save_data_col = pd.concat(save_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccaa2e-de47-4dc1-9713-0bc59ed3851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dataframes in list to one dataframe\n",
    "combined_data = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993984ec-ca33-47de-9e98-b677b16258bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe with all collumns to csv to save for later\n",
    "save_data_col.to_csv('save_data_col.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82582ae7-b07a-494c-bacf-d79ecee576c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to csv\n",
    "combined_data.to_csv('interpolated_meter_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bf447-12b9-43f2-9c77-83e9bd039cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce184da-6e00-40b8-a16c-d568ba738433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of meters and first timestamp in dataset\n",
    "df = pd.read_csv('.csv', encoding=\"utf-8\")\n",
    "print(df['meter_name'].unique())\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cd8170-b0e2-42c1-8625-2a11b04d867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample of interpolated data for admin_serv_1 2025-09-10\n",
    "df = pd.read_csv('interpolated_meter_data.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44731b2f-f1e2-4d09-a0c5-64b612684834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime        meter_name  total_watt_hour  interpolated\n",
      "0  2025-07-23 09:40:50  admin_serv_1_mtr        1381508.0         False\n",
      "1  2025-07-23 09:41:54  admin_serv_1_mtr        1381508.0         False\n",
      "2  2025-07-23 09:42:59  admin_serv_1_mtr        1381509.0         False\n",
      "3  2025-07-23 09:44:03  admin_serv_1_mtr        1381510.0         False\n",
      "4  2025-07-23 09:45:00  admin_serv_1_mtr        1381510.0          True\n",
      "5  2025-07-23 09:45:08  admin_serv_1_mtr        1381510.0         False\n",
      "6  2025-07-23 09:46:14  admin_serv_1_mtr        1381511.0         False\n",
      "7  2025-07-23 09:47:20  admin_serv_1_mtr        1381511.0         False\n",
      "8  2025-07-23 09:48:26  admin_serv_1_mtr        1381512.0         False\n",
      "9  2025-07-23 09:48:39  admin_serv_1_mtr        1381512.0         False\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e4905c-a153-4269-9d72-feebeb2a0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "date = pd.to_datetime('2025-09-10').date()\n",
    "sample_data = (df[(df['datetime'].dt.date == date) & (df['meter_name'] == 'admin_serv_1_mtr')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374ee14d-68e8-4b3e-ae1b-a4fa86e19f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.to_csv('sample_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afecbf7-1c6c-4223-a40e-a07b0468ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
