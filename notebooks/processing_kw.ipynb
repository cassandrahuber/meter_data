{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1e20b-cf22-4219-bcc5-effc2ff13f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Brian's kw data (data already extracted from MeterDataTest folder)\n",
    "# Complete this before second part of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b420a-c2b4-4545-b383-142fe0add85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fa433-bb41-4115-bc95-5f28840b5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from processing_kw import load_data, process_kw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da72b3-5422-4cf0-8aca-55e98356b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data input csv\n",
    "data_path = 'save_data_col.csv'\n",
    "\n",
    "# guide of the meters with their meter model types\n",
    "info_path = 'all_headers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037864ac-6af6-4176-a7fd-4f0b9648ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load meter data and info from csvs into dataframes, cleaned and reformatted\n",
    "df, info_df = load_data(data_path, info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6359948-6bde-4c4b-844c-31be93aae8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data for only dates sept 7-9\n",
    "#df = df[df['datetime'].dt.date.isin([\n",
    "#    pd.to_datetime('2025-09-07').date(),\n",
    "#    pd.to_datetime('2025-09-08').date(),\n",
    "#    pd.to_datetime('2025-09-09').date()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b50da-f740-4cee-81a6-9408f5af3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed kw data in dataframe\n",
    "result_df = process_kw_data(df, info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57882c-e27f-477c-8556-871efdf270e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv of processed data\n",
    "result_df.to_csv('processed_kw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d265b3-4c81-4034-9976-d909c2f74bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622db56-ea50-44f8-8649-f672bd21adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare processed brians kw ('mean_kw') data to auroras kw ('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e18baa8-cf5e-41b3-8e11-04e0729c7df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from processing_kw import load_data_for_comparison, create_plots_pdf, get_comparison_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1aa910c-4663-4f31-a6fa-8267af0afcbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 0001-01-01 05:30:00, at position 152935. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOverflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:415\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOverflowError\u001b[39m: Overflow occurred in npy_datetimestruct_to_datetime",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutOfBoundsDatetime\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m aurora_csv = \u001b[33m'\u001b[39m\u001b[33m1Untitled.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# create merged dataframe of the input csvs and get the list of meters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m merged_df, meters = \u001b[43mload_data_for_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrian_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maurora_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# optional create csv of merged dataframe\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#merged_df.to_csv('merged_brian_aurora.csv')\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/meter_data/processing_kw.py:83\u001b[39m, in \u001b[36mload_data_for_comparison\u001b[39m\u001b[34m(brian_csv, aurora_csv)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# convert datetime column to datetime type\u001b[39;00m\n\u001b[32m     82\u001b[39m brian_df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(brian_df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m aurora_df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43maurora_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdatetime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# merge the dataframes together on meter_name and datetime\u001b[39;00m\n\u001b[32m     86\u001b[39m merged_df = pd.merge(brian_df, aurora_df, on=[\u001b[33m'\u001b[39m\u001b[33mmeter_name\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m], how=\u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/meter_data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1068\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1066\u001b[39m             result = arg.tz_localize(\u001b[33m\"\u001b[39m\u001b[33mutc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m     cache_array = \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array.empty:\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/meter_data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:249\u001b[39m, in \u001b[36m_maybe_cache\u001b[39m\u001b[34m(arg, format, cache, convert_listlike)\u001b[39m\n\u001b[32m    247\u001b[39m unique_dates = unique(arg)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) < \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     cache_dates = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/meter_data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/meter_data/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:469\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    459\u001b[39m     arg,\n\u001b[32m    460\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    465\u001b[39m ) -> Index:\n\u001b[32m    466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    471\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:418\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOutOfBoundsDatetime\u001b[39m: Out of bounds nanosecond timestamp: 0001-01-01 05:30:00, at position 152935. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# brian input csv\n",
    "#brian_csv = 'sept07-09_kw.csv'\n",
    "brian_csv = 'processed_kw.csv'\n",
    "\n",
    "# aurora input csv\n",
    "#aurora_csv = 'blue_pillar_data.csv'\n",
    "aurora_csv = 'aurora_processed_kw.csv'\n",
    "\n",
    "# create merged dataframe of the input csvs and get the list of meters\n",
    "merged_df, meters = load_data_for_comparison(brian_csv, aurora_csv)\n",
    "\n",
    "# optional create csv of merged dataframe\n",
    "#merged_df.to_csv('merged_brian_aurora.csv', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1758e0-5a4c-41d8-8912-2f287c0cd438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a43a4c-59fb-4715-a809-44e234bd6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pdf of plots comparing brian vs aurora kw data per meter\n",
    "create_plots_pdf(merged_df, meters, 'aurora_vs_curr.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02014b-ddb2-44ff-8c95-bf8798856fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of info summarizing comparison brian vs aurora kw data per meter\n",
    "info_df = get_comparison_info(merged_df, meters)\n",
    "\n",
    "# create csv of comparison info dataframe\n",
    "info_df.to_csv('brian_bp_comparison_info.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
